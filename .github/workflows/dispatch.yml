# Trigger the execution of copy workflow in batches.
# This workflow is needed since GitHub Actions limits the matrix size to 256 jobs.
# We use one job per repository per batch.

name: Dispatch

on:
  workflow_dispatch:
    override:
      description: "Defaults override to use for each target"
      required: false
      default: '{}'
    branch:
      description: "Branch to deploy to in each target"
      required: false
      default: 'web3-bot/sync'
    script:
      description: "Script to run in each target"
      required: false
      default: 'copy-templates.sh'

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

env:
  # Number of repositories in a batch.
  # Matrix jobs within a copy workflow run are run in parallel.
  # 256 is the upper limit on the number of matrix jobs.
  # Batching too many repositories together can result in
  #  could not create workflow dispatch event: HTTP 422: inputs are too large.
  # This value should be higher than max-parallel in copy workflow.
  MAX_REPOS_PER_WORKFLOW: 100
  # Number of seconds to wait before starting to watch copy workflow run.
  # Unfortunately, the interval on the watch is not configurable.
  # The delay helps us save on GH API requests.
  WORKFLOW_COMPLETION_CHECK_DELAY: 60

jobs:
  matrix:
    name: Batch targets
    runs-on: ubuntu-latest
    outputs:
      batches: ${{ steps.matrix.outputs.result }}
    steps:
      - id: matrix
        uses: actions/github-script@v6
        with:
          github-token: ${{ secrets.WEB3_BOT_GITHUB_TOKEN }}
          retries: 0
          script: |
            const request = async function(req, opts) {
              try {
                return await req(opts)
              } catch(err) {
                opts.request.retries = (opts.request.retries || 0) + 1
                if (err.status === 403) {
                  if (err.response.headers['x-ratelimit-remaining'] === '0') {
                    const retryAfter = err.response.headers['x-ratelimit-reset'] - Math.floor(Date.now() / 1000) || 1
                    core.info(`Rate limit exceeded, retrying in ${retryAfter} seconds`)
                    await new Promise(resolve => setTimeout(resolve, retryAfter * 1000))
                    return request(req, opts)
                  }
                  if (err.message.toLowerCase().includes('secondary rate limit')) {
                    const retryAfter = Math.pow(2, opts.request.retries)
                    core.info(`Secondary rate limit exceeded, retrying in ${retryAfter} seconds`)
                    await new Promise(resolve => setTimeout(resolve, retryAfter * 1000))
                    return request(req, opts)
                  }
                }
                throw err
              }
            }
            github.hook.wrap('request', request)
            core.info(`Looking for repositories the user has direct access to`)
            const items = await github.paginate(github.rest.repos.listForAuthenticatedUser, {
              affiliation: 'collaborator'
            })
            const maxReposPerWorkflow = parseInt(process.env.MAX_REPOS_PER_WORKFLOW)
            const batches = []
            let batch = []
            for (const item of items) {
              batch.push(item.full_name)
              if (batch.length === maxReposPerWorkflow) {
                batches.push({
                  key: batches.length,
                  value: batch
                })
                batch = []
              }
            }
            if (batch.length > 0) {
              batches.push({
                key: batches.length,
                value: batch
              })
            }
            return batches
  dispatch:
    needs: [ matrix ]
    name: Dispatch copy workflow(batch ${{ matrix.cfg.key }})
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        # We end up with multiple "dispatch" jobs,
        # one per BATCHES "key" chunk above with a "value" array.
        # For each "dispatch" job, matrix.cfg.value is an array, like:
        #
        #   [
        #     "repo1",
        #     "repo2"
        #   ]
        #
        # The triggered copy workflow runs use that final array as their matrix.
        # Since max-parallel here is 1, we'll end up with at most max-parallel from copy workflow + 1 parallel jobs.
        # 20 is the upper limit on parallel jobs on a free plan.
        cfg: ${{ fromJSON(needs.matrix.outputs.batches) }}
      max-parallel: 1
    env:
      GITHUB_TOKEN: ${{ secrets.WEB3_BOT_GITHUB_TOKEN }}
      WORKFLOW_YML: copy-workflow.yml
      WORKFLOW_REPO: protocol/.github
    steps:
      - id: dispatch
        name: Dispatch copy workflow
        env:
          TARGETS: ${{ toJSON(matrix.cfg.value) }}
          OVERRIDE: ${{ github.event.inputs.override }}
          BRANCH: ${{ github.event.inputs.branch }}
          SCRIPT: ${{ github.event.inputs.script }}
        run: |
          start_date="$(date +%s)"
          gh workflow run "$WORKFLOW_YML" --ref "$GITHUB_REF" --repo "$WORKFLOW_REPO" --field "targets=$TARGETS" --field "override=$OVERRIDE" --field "branch=$BRANCH" --field "script=$SCRIPT
          echo "start_date=$start_date" >> $GITHUB_OUTPUT
      - id: run
        name: Wait for copy workflow run to start
        env:
          START_DATE: ${{ steps.dispatch.outputs.start_date }}
        run: |
          # checks every 3 seconds until the most recent copy workflow run's created_at is later than this job's start_date
          while sleep 3; do
            run="$(gh api "/repos/$WORKFLOW_REPO/actions/workflows/$WORKFLOW_YML/runs?per_page=1" --jq '.workflow_runs[0]')"
            # nothing to check if no copy workflow run was returned
            if [[ ! -z "$run" ]]; then
              run_start_date="$(date --date="$(jq -r '.created_at' <<< "$run")" +%s)"
              if [[ "$run_start_date" > "$START_DATE" ]]; then
                echo "id=$(jq -r '.id' <<< "$run")" >> $GITHUB_OUTPUT
                break
              fi
            fi
          done
      - name: Wait for copy workflow run to complete
        env:
          RUN_ID: ${{ steps.run.outputs.id }}
        run: |
          # delays checking copy workflow's run status to save on GH API requests
          sleep $WORKFLOW_COMPLETION_CHECK_DELAY

          # checks every 3 seconds until the copy workflow run's status is completed
          # redirects the stdout to /dev/null because it is very chatty
          gh run watch "$RUN_ID" --repo "$WORKFLOW_REPO" > /dev/null
